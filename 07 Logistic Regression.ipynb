{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with CSV files\n",
    "class DiabetesDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./datasets/diabetes.csv',\n",
    "                        delimiter=',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.from_numpy(xy[:, 0:-1])\n",
    "        self.y_data = torch.from_numpy(xy[:, [-1]])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset()\n",
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(8, 6)\n",
    "        self.l2 = torch.nn.Linear(6, 4)\n",
    "        self.l3 = torch.nn.Linear(4, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.sigmoid(self.l1(x))\n",
    "        out2 = self.sigmoid(self.l2(out1))\n",
    "        y_pred = self.sigmoid(self.l3(out2))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/functional.py:54: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.6100521683692932\n",
      "0 1 0.6785364151000977\n",
      "0 2 0.6513803601264954\n",
      "0 3 0.7018906474113464\n",
      "0 4 0.6517715454101562\n",
      "0 5 0.677361786365509\n",
      "0 6 0.6502419114112854\n",
      "0 7 0.6635555624961853\n",
      "0 8 0.6765504479408264\n",
      "0 9 0.6509267091751099\n",
      "0 10 0.6901815533638\n",
      "0 11 0.6628472805023193\n",
      "0 12 0.5698296427726746\n",
      "0 13 0.6165542006492615\n",
      "0 14 0.6155514121055603\n",
      "0 15 0.6128129959106445\n",
      "0 16 0.6621354222297668\n",
      "0 17 0.7128270864486694\n",
      "0 18 0.6468894481658936\n",
      "0 19 0.6619017720222473\n",
      "0 20 0.6616584062576294\n",
      "0 21 0.7282209992408752\n",
      "0 22 0.6311601996421814\n",
      "0 23 0.5512107610702515\n",
      "1 0 0.5744782090187073\n",
      "1 1 0.6627934575080872\n",
      "1 2 0.6816314458847046\n",
      "1 3 0.5725534558296204\n",
      "1 4 0.6244903802871704\n",
      "1 5 0.6240933537483215\n",
      "1 6 0.5860903859138489\n",
      "1 7 0.7031939625740051\n",
      "1 8 0.7614943981170654\n",
      "1 9 0.6266109347343445\n",
      "1 10 0.6613290309906006\n",
      "1 11 0.6829395294189453\n",
      "1 12 0.6085311770439148\n",
      "1 13 0.6636718511581421\n",
      "1 14 0.6995416283607483\n",
      "1 15 0.6266451478004456\n",
      "1 16 0.6437571048736572\n",
      "1 17 0.6989393830299377\n",
      "1 18 0.6275165677070618\n",
      "1 19 0.6084559559822083\n",
      "1 20 0.6443083882331848\n",
      "1 21 0.6437588930130005\n",
      "1 22 0.6243985891342163\n",
      "1 23 0.7012567520141602\n",
      "2 0 0.6819859743118286\n",
      "2 1 0.6799750924110413\n",
      "2 2 0.6451982855796814\n",
      "2 3 0.62599778175354\n",
      "2 4 0.62567538022995\n",
      "2 5 0.6264403462409973\n",
      "2 6 0.6241956949234009\n",
      "2 7 0.701827883720398\n",
      "2 8 0.6995062828063965\n",
      "2 9 0.7347288727760315\n",
      "2 10 0.6624548435211182\n",
      "2 11 0.6963672637939453\n",
      "2 12 0.6786684989929199\n",
      "2 13 0.6614663600921631\n",
      "2 14 0.6129921078681946\n",
      "2 15 0.6622411012649536\n",
      "2 16 0.5426687002182007\n",
      "2 17 0.6258316040039062\n",
      "2 18 0.5690475702285767\n",
      "2 19 0.643592357635498\n",
      "2 20 0.5845481753349304\n",
      "2 21 0.6033445000648499\n",
      "2 22 0.6026454567909241\n",
      "2 23 0.749222993850708\n",
      "3 0 0.5837817192077637\n",
      "3 1 0.6439030766487122\n",
      "3 2 0.5613592863082886\n",
      "3 3 0.6438124179840088\n",
      "3 4 0.6436547636985779\n",
      "3 5 0.6653048992156982\n",
      "3 6 0.6855893135070801\n",
      "3 7 0.6638760566711426\n",
      "3 8 0.663556694984436\n",
      "3 9 0.6221771240234375\n",
      "3 10 0.6853825449943542\n",
      "3 11 0.704014778137207\n",
      "3 12 0.6436333656311035\n",
      "3 13 0.5854334235191345\n",
      "3 14 0.5832797288894653\n",
      "3 15 0.7056788206100464\n",
      "3 16 0.7241563200950623\n",
      "3 17 0.7012801170349121\n",
      "3 18 0.6065621376037598\n",
      "3 19 0.6818299293518066\n",
      "3 20 0.6246359348297119\n",
      "3 21 0.6247905492782593\n",
      "3 22 0.6053066253662109\n",
      "3 23 0.6838222742080688\n",
      "4 0 0.7794983386993408\n",
      "4 1 0.6629818081855774\n",
      "4 2 0.698410153388977\n",
      "4 3 0.6619625091552734\n",
      "4 4 0.627547025680542\n",
      "4 5 0.6264718770980835\n",
      "4 6 0.6258600354194641\n",
      "4 7 0.6258798241615295\n",
      "4 8 0.6623225808143616\n",
      "4 9 0.6989107131958008\n",
      "4 10 0.6798055768013\n",
      "4 11 0.5913217663764954\n",
      "4 12 0.605998158454895\n",
      "4 13 0.7191892266273499\n",
      "4 14 0.5531013011932373\n",
      "4 15 0.6438528299331665\n",
      "4 16 0.5657030344009399\n",
      "4 17 0.6231013536453247\n",
      "4 18 0.6021776795387268\n",
      "4 19 0.6858109831809998\n",
      "4 20 0.6029543876647949\n",
      "4 21 0.6232842206954956\n",
      "4 22 0.6648107171058655\n",
      "4 23 0.7055861949920654\n",
      "5 0 0.6642005443572998\n",
      "5 1 0.6625217199325562\n",
      "5 2 0.6237999796867371\n",
      "5 3 0.6831358075141907\n",
      "5 4 0.662024974822998\n",
      "5 5 0.6442661285400391\n",
      "5 6 0.6240442395210266\n",
      "5 7 0.6043503880500793\n",
      "5 8 0.602950394153595\n",
      "5 9 0.5615413188934326\n",
      "5 10 0.5790488123893738\n",
      "5 11 0.7319254875183105\n",
      "5 12 0.7070499658584595\n",
      "5 13 0.6843666434288025\n",
      "5 14 0.5835584998130798\n",
      "5 15 0.6230985522270203\n",
      "5 16 0.7265544533729553\n",
      "5 17 0.6833904385566711\n",
      "5 18 0.5844871401786804\n",
      "5 19 0.6230555772781372\n",
      "5 20 0.6431822776794434\n",
      "5 21 0.6635979413986206\n",
      "5 22 0.74437415599823\n",
      "5 23 0.6245895028114319\n",
      "6 0 0.7016376852989197\n",
      "6 1 0.6432843804359436\n",
      "6 2 0.606398344039917\n",
      "6 3 0.6433514952659607\n",
      "6 4 0.6242153644561768\n",
      "6 5 0.6434343457221985\n",
      "6 6 0.5256344079971313\n",
      "6 7 0.6008478403091431\n",
      "6 8 0.7289720773696899\n",
      "6 9 0.7457133531570435\n",
      "6 10 0.7017276287078857\n",
      "6 11 0.661949872970581\n",
      "6 12 0.6250561475753784\n",
      "6 13 0.7380855679512024\n",
      "6 14 0.6077985167503357\n",
      "6 15 0.5880264043807983\n",
      "6 16 0.6048370003700256\n",
      "6 17 0.7226824164390564\n",
      "6 18 0.5482711791992188\n",
      "6 19 0.7434505224227905\n",
      "6 20 0.6243550181388855\n",
      "6 21 0.5853011608123779\n",
      "6 22 0.5836636424064636\n",
      "6 23 0.7472185492515564\n",
      "7 0 0.7215362191200256\n",
      "7 1 0.6813656091690063\n",
      "7 2 0.6632941365242004\n",
      "7 3 0.6255627274513245\n",
      "7 4 0.6065282225608826\n",
      "7 5 0.7195810079574585\n",
      "7 6 0.6247789859771729\n",
      "7 7 0.605925440788269\n",
      "7 8 0.6049127578735352\n",
      "7 9 0.6242359280586243\n",
      "7 10 0.6241498589515686\n",
      "7 11 0.7432758808135986\n",
      "7 12 0.6045919060707092\n",
      "7 13 0.6042304039001465\n",
      "7 14 0.6429186463356018\n",
      "7 15 0.683631420135498\n",
      "7 16 0.7027533650398254\n",
      "7 17 0.5862452983856201\n",
      "7 18 0.7602754235267639\n",
      "7 19 0.5503627061843872\n",
      "7 20 0.5846772789955139\n",
      "7 21 0.6225529909133911\n",
      "7 22 0.6853032112121582\n",
      "7 23 0.6630408763885498\n",
      "8 0 0.6631888747215271\n",
      "8 1 0.6226269602775574\n",
      "8 2 0.5829557776451111\n",
      "8 3 0.6018991470336914\n",
      "8 4 0.7065412402153015\n",
      "8 5 0.6642515659332275\n",
      "8 6 0.6623414754867554\n",
      "8 7 0.7422530055046082\n",
      "8 8 0.6061720848083496\n",
      "8 9 0.6055591106414795\n",
      "8 10 0.6223425269126892\n",
      "8 11 0.7026700377464294\n",
      "8 12 0.6243489980697632\n",
      "8 13 0.6816842555999756\n",
      "8 14 0.6628775000572205\n",
      "8 15 0.7004864811897278\n",
      "8 16 0.643334150314331\n",
      "8 17 0.6056144833564758\n",
      "8 18 0.6623404622077942\n",
      "8 19 0.6633399128913879\n",
      "8 20 0.6430814266204834\n",
      "8 21 0.624131441116333\n",
      "8 22 0.624445915222168\n",
      "8 23 0.6055790781974792\n",
      "9 0 0.743084728717804\n",
      "9 1 0.5680366158485413\n",
      "9 2 0.6418632864952087\n",
      "9 3 0.7020623087882996\n",
      "9 4 0.6422746181488037\n",
      "9 5 0.7020609378814697\n",
      "9 6 0.625266432762146\n",
      "9 7 0.6052641868591309\n",
      "9 8 0.6041155457496643\n",
      "9 9 0.6229882836341858\n",
      "9 10 0.5835747122764587\n",
      "9 11 0.6845409870147705\n",
      "9 12 0.6629586219787598\n",
      "9 13 0.6827051043510437\n",
      "9 14 0.6225801706314087\n",
      "9 15 0.723351776599884\n",
      "9 16 0.6054412126541138\n",
      "9 17 0.7017875909805298\n",
      "9 18 0.624727725982666\n",
      "9 19 0.6625325083732605\n",
      "9 20 0.6619536876678467\n",
      "9 21 0.5862813591957092\n",
      "9 22 0.6033968925476074\n",
      "9 23 0.6632956266403198\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Forward pass: Compute predicted y by passing x to the model\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        # Compute and print loss\n",
    "        loss = criterion(y_pred, labels)\n",
    "        print(epoch, i, loss.item())\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
