{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# nn.Module has all the layers of a Neural Network\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        \"\"\"\n",
    "        First convolution layer\n",
    "        One image 32 x 32 -- one input layer, 6 feature maps or filters of size 28 x 28 \n",
    "        -- 6 output layers, 5 x 5  -- filter size\n",
    "        \n",
    "        \"\"\"\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        \"\"\"\n",
    "        Second convolution layer\n",
    "        6 feature maps -- input, 16 feature maps or filters of size 10 x 10 (max-pooling \n",
    "        is done is between which gives the layer of size 6 x 14 x 14)\n",
    "        \n",
    "        \"\"\"\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        # Fully connected layers - prior to which subsampling or maxpooling is done giving a lyer of size -- 16 x 5 x 5\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        # The other two FC layers\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    \"\"\"\n",
    "    We need to only define the forward function, backward function is automatically defined by \n",
    "    autograd.\n",
    "    A forward function defines the functions that need to be performed, hence, max pooling and \n",
    "    ReLU are applied in this function, therfore, not written in the __init__ method.\n",
    "    The forward function isn't explicity called since the hooks are already defined in the \n",
    "    nn.Module class, the super class.\n",
    "    \n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        # 2 x 2 is the maxpool filter size - hence, 6 x 28 x 28 turns to 6 x 14 x 14.\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        # If the max pool window is a square, then a single number suffices\n",
    "        # 16 x 10 x 10 changes to 16 x 5 x 5\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        # self.num_of_flat_features = 400 -- 16 x 5 x 5\n",
    "        x = x.view(-1, self.num_of_flat_features(x))\n",
    "        # print(x.size()) -- torch.tensor([1, 400])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_of_flat_features(self,x):\n",
    "        # x.size() - 1 x 16 x 5 x 5 -- 1 is the batch size\n",
    "        # size - 16 x 5 x 5\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = NeuralNet()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param -- Learnable parameters of a model\n",
    "param = list(net.parameters())\n",
    "len(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(param[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A detailed view of parameters\n",
    "param = list(net.named_parameters())\n",
    "len(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight tensor([[[[-0.1973,  0.1441, -0.1931,  0.1865, -0.1701],\n",
      "          [-0.1249, -0.1571, -0.1246,  0.1344, -0.1944],\n",
      "          [-0.1563, -0.0145, -0.1876,  0.0460,  0.1662],\n",
      "          [-0.1878,  0.0535, -0.0005,  0.0971,  0.0039],\n",
      "          [ 0.1449, -0.1251, -0.0664, -0.1351,  0.1475]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0729, -0.1037, -0.1384,  0.1544,  0.0736],\n",
      "          [-0.1383, -0.0221,  0.0405,  0.1948, -0.0636],\n",
      "          [-0.0050, -0.0425, -0.0581, -0.1180,  0.1647],\n",
      "          [-0.1828,  0.1465,  0.1235,  0.0464, -0.0210],\n",
      "          [ 0.0247,  0.1393,  0.0507, -0.0561,  0.0082]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0055,  0.1133,  0.1573, -0.1209, -0.0170],\n",
      "          [-0.0975,  0.0385,  0.1862, -0.0741, -0.1965],\n",
      "          [ 0.0360,  0.0911,  0.1235,  0.1954, -0.1332],\n",
      "          [-0.0523, -0.1640, -0.1746,  0.0640, -0.1908],\n",
      "          [-0.0339, -0.0097,  0.1895,  0.0439, -0.0177]]],\n",
      "\n",
      "\n",
      "        [[[-0.0361,  0.1131, -0.1163,  0.0054, -0.1796],\n",
      "          [ 0.1649,  0.0555,  0.1771, -0.1388,  0.1147],\n",
      "          [ 0.0114,  0.1867, -0.0531,  0.0742, -0.1032],\n",
      "          [-0.1324, -0.0095,  0.0813, -0.0769,  0.0739],\n",
      "          [ 0.0060, -0.0953,  0.1314,  0.1945,  0.1986]]],\n",
      "\n",
      "\n",
      "        [[[-0.0949,  0.0811, -0.0998, -0.1612,  0.0733],\n",
      "          [ 0.1569,  0.1151,  0.0385,  0.0133,  0.0131],\n",
      "          [-0.1167, -0.0103,  0.1642, -0.0797,  0.1259],\n",
      "          [-0.0168,  0.0750, -0.1733,  0.0046, -0.1005],\n",
      "          [ 0.1860, -0.0434, -0.1707,  0.0587,  0.1656]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0670, -0.1930,  0.1697, -0.0362,  0.1706],\n",
      "          [ 0.1234, -0.1967, -0.1115, -0.0984,  0.1938],\n",
      "          [-0.0875,  0.1735,  0.1365,  0.0380,  0.1955],\n",
      "          [-0.1215, -0.1133,  0.0060,  0.1260, -0.1942],\n",
      "          [-0.0865, -0.0401,  0.1643,  0.0874, -0.0626]]]])\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "        print(name, param.data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0015,  0.1118,  0.1037, -0.1606, -0.1546,  0.0788,  0.0225,  0.0484,\n",
       "         -0.0402,  0.1156]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn. Conv2d takes in a 4D tensor - nSamples x nChannels x Height x Width. \n",
    "input = torch.randn(1,1,32,32)\n",
    "out = net(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9376, grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.randn(10)\n",
    "target = target.view(1,-1)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(target, out)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeanBackward1 object at 0x106521160>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x1065213c8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn.next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SubBackward0 object at 0x1065216d8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <MeanBackward1 object at 0x106521cc0>\n",
      "**** <PowBackward0 object at 0x106521c50>\n",
      "******** <SubBackward0 object at 0x106521940>\n",
      "************ <ThAddmmBackward object at 0x106521e80>\n",
      "**************** <ExpandBackward object at 0x106521e48>\n",
      "******************** <AccumulateGrad object at 0x107b6f320>\n",
      "**************** <ReluBackward object at 0x106521ef0>\n",
      "******************** <ThAddmmBackward object at 0x107b6f320>\n",
      "************************ <ExpandBackward object at 0x10c4f9390>\n",
      "**************************** <AccumulateGrad object at 0x10c4f9470>\n",
      "************************ <ReluBackward object at 0x10c4f93c8>\n",
      "**************************** <ThAddmmBackward object at 0x10c4f9470>\n",
      "******************************** <ExpandBackward object at 0x10c4f9588>\n",
      "************************************ <AccumulateGrad object at 0x10c4f9668>\n",
      "******************************** <ViewBackward object at 0x10c4f95c0>\n",
      "************************************ <MaxPool2DWithIndicesBackward object at 0x10c4f9668>\n",
      "**************************************** <ReluBackward object at 0x10c4f96d8>\n",
      "******************************************** <ThnnConv2DBackward object at 0x10c4f9748>\n",
      "************************************************ <MaxPool2DWithIndicesBackward object at 0x10c4f97f0>\n",
      "**************************************************** <ReluBackward object at 0x10c4f98d0>\n",
      "******************************************************** <ThnnConv2DBackward object at 0x10c4f9978>\n",
      "************************************************************ <AccumulateGrad object at 0x10c4f9a20>\n",
      "************************************************************ <AccumulateGrad object at 0x10c4f9a58>\n",
      "************************************************ <AccumulateGrad object at 0x10c4f9828>\n",
      "************************************************ <AccumulateGrad object at 0x10c4f9860>\n",
      "******************************** <TBackward object at 0x10c4f95f8>\n",
      "************************************ <AccumulateGrad object at 0x10c4f9668>\n",
      "************************ <TBackward object at 0x10c4f9400>\n",
      "**************************** <AccumulateGrad object at 0x10c4f9320>\n",
      "**************** <TBackward object at 0x106521f28>\n",
      "******************** <AccumulateGrad object at 0x107b6f320>\n"
     ]
    }
   ],
   "source": [
    "# Prints the whole stack of Graph of computations\n",
    "def print_graph(g, level=0):\n",
    "    if g == None: return\n",
    "    print('*'*level*4, g)\n",
    "    for subg in g.next_functions:\n",
    "        print_graph(subg[0], level+1)\n",
    "\n",
    "print_graph(loss.grad_fn, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.zero_grad()\n",
    "# print('conv1.bias.grad before backprop')\n",
    "# print(net.conv1.bias.grad)\n",
    "# Output:\n",
    "# conv1.bias.grad before backprop\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.backward()\n",
    "# print('conv1.bias.grad after backward')\n",
    "# print(net.conv1.bias.grad)\n",
    "# Output:\n",
    "# conv1.bias.grad after backward\n",
    "# tensor([-0.0182,  0.0038,  0.0034,  0.0181,  0.0007,  0.0107])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss.backward()\n",
    "# lr = 0.01\n",
    "# for f in net.parameters():\n",
    "#    f.data.sub_(f.grad.data * lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not just a simple weight updation rule, w -= lr * grad, instead we can use optimization \n",
    "techniques for better accuracy, say SGD, Nesterov-SGD, Adam etc.\n",
    "Backpropagation + Loss + updation of weights\n",
    "\n",
    "\"\"\"\n",
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# While traning,\n",
    "optimizer.zero_grad()\n",
    "out = net(input)\n",
    "loss = criterion(loss, out)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
